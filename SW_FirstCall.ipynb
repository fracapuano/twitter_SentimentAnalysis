{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Notebook produced for the Assignment of the Data Science Lab course at Politecnico di Torino by \n",
    "\n",
    "- Francesco Capuano, s295366\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importations "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import datatable as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score, make_scorer, plot_confusion_matrix\n",
    "import pprint\n",
    "\n",
    "from utils import *\n",
    "tqdm.pandas()\n",
    "\n",
    "rs = 23042000\n",
    "np.random.seed(rs)\n",
    "\n",
    "main_PATH = os.getcwd()\n",
    "os.chdir(main_PATH + \"/data\")\n",
    "data_PATH = os.getcwd()\n",
    "\n",
    "#importing the data\n",
    "dev = dt.fread(\"development.csv\").to_pandas()\n",
    "ev = dt.fread(\"evaluation.csv\").to_pandas()\n",
    "\n",
    "os.chdir(main_PATH)\n",
    "\n",
    "#replacing the sentiment \n",
    "dev.sentiment.replace([True, False], [1,0], inplace = True)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:51:33.827656Z",
     "start_time": "2022-01-18T16:51:29.202076Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"***** NEEDED PACKAGES *****\")\n",
    "print(\"datatable version:\", dt.__version__)\n",
    "print(\"pandas version:\", pd.__version__)\n",
    "print(\"numpy version:\", np.__version__)\n",
    "print(\"seaborn version:\", sns.__version__)\n",
    "import matplotlib\n",
    "print(\"matplotlib version:\", matplotlib.__version__)\n",
    "import sklearn\n",
    "print(\"scikit-learn version:\", sklearn.__version__)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:51:33.839181Z",
     "start_time": "2022-01-18T16:51:33.832307Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Exploration and Data Cleaning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dev.flag.value_counts()\n",
    "#the only value for flag field is \"NO_QUERY\""
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:51:33.882866Z",
     "start_time": "2022-01-18T16:51:33.845226Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#obtaining the number of characters each tweet is composed\n",
    "dev[\"NumberOfChars\"] = dev.text.progress_apply(len)\n",
    "\n",
    "#concluding whether or not one index present a tweet that is exceeding the 140 chrs limit. \n",
    "dev[\"ExceedsBound\"] = dev.NumberOfChars.progress_apply(lambda x: 1 if x > 140 else 0)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:51:34.781440Z",
     "start_time": "2022-01-18T16:51:33.885606Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (6,4))\n",
    "\n",
    "#semantic informations\n",
    "plt.subplot(1,2,1)\n",
    "ax[0] = sns.histplot(data = dev.ExceedsBound, stat = \"count\")\n",
    "\n",
    "ax[0].set_yscale(\"log\")\n",
    "\n",
    "ax[0].set_xticks([0,1])\n",
    "ax[0].set_yticks([2538, 222456])\n",
    "\n",
    "ax[0].set_xticklabels([\"length consistent\", \"length exceeding\"], fontdict = {\"fontsize\": 12}, rotation = 10)\n",
    "ax[0].set_yticklabels([\"2538\", \"222456\"],  fontdict = {\"fontsize\": 12}, rotation = 10)\n",
    "\n",
    "ax[0].set_xlabel(\"\")\n",
    "ax[0].set_ylabel(\"Number of tweets\")\n",
    "\n",
    "ax[0].grid(which = \"both\")\n",
    "\n",
    "#statistic information\n",
    "plt.subplot(1,2,2)\n",
    "ax[1] = sns.boxplot(data = dev.NumberOfChars)\n",
    "ax[1].set_xlabel(\"\")\n",
    "\n",
    "secax = ax[1].secondary_yaxis(\"right\")\n",
    "secax.set_yticks([\n",
    "    dev.NumberOfChars.describe()[\"25%\"], \n",
    "    dev.NumberOfChars.describe()[\"50%\"], \n",
    "    dev.NumberOfChars.describe()[\"75%\"], \n",
    "    140]\n",
    ")\n",
    "secax.set_yticklabels([\"25%\", \"50%\", \"75%\", \"140 chrs bound\"],  fontdict = {\"fontsize\": 10})\n",
    "\n",
    "ax[1].axhline(140, color = \"red\", linestyle = \"--\", linewidth = 1.25)\n",
    "ax[1].set_xticks([])\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(\"NumberOfChars.svg\")"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:51:35.675613Z",
     "start_time": "2022-01-18T16:51:34.783792Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With respect to the number of words, even if the value \"140\" is stastically valid (as shown in the left part of Figure (NumberOfChars), it is important to notice that it is not semantically correct, considering the strict bound of the number of characters imposed by Twitter back in 2009. Hence, all the 2538 tweets that are exceding this bound should be removed as they represent data points that are non consistent with the domain of interest."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#dropping the dirty data points\n",
    "tooLongIdx = dev[dev[\"ExceedsBound\"] == 1].index\n",
    "dev.drop(index = tooLongIdx, inplace = True)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:51:35.788657Z",
     "start_time": "2022-01-18T16:51:35.678805Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#building up a dataframe containing informations on the Positive/Negative ratio per User.\n",
    "PosPerUser = dev.loc[:, [\"user\", \"sentiment\"]].groupby(by = \"user\").sum()\n",
    "TotPerUser = dev.loc[:, [\"user\", \"sentiment\"]].groupby(by = \"user\").count()\n",
    "SntPerUser = pd.concat([PosPerUser, TotPerUser], axis = 1)\n",
    "\n",
    "SntPerUser.columns = [\"PositiveTweets\", \"TotalTweets\"]\n",
    "SntPerUser[\"PosRatio\"] = SntPerUser.apply(lambda x: x[\"PositiveTweets\"]/x[\"TotalTweets\"], axis = 1)\n",
    "\n",
    "#characterizing a user based on the fraction of positive tweets he/she posts. \n",
    "SntPerUser[\"ExtremeOrNot\"] = SntPerUser.PosRatio.progress_apply(lambda x: 0.75 if (x < 0.10 or x > 0.90) else 0.25)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:51:36.281307Z",
     "start_time": "2022-01-18T16:51:35.798474Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = (6,4))\n",
    "plt.subplot(1,2,1)\n",
    "ax[0] = SntPerUser.PosRatio.hist(bins = 50)\n",
    "ax[0].set_title(\"Distribution of Positive-Tweetters\", fontdict = {\"fontsize\": 10})\n",
    "ax[0].set_xlabel(\"Percentage of Positive Tweets\", fontdict = {\"fontsize\": 12})\n",
    "ax[0].set_ylabel(\"Number of users\", fontdict = {\"fontsize\": 12})\n",
    "ax[0].grid(True)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "ax[1] = SntPerUser.ExtremeOrNot.hist()\n",
    "ax[1].set_title(\"Distribution of Highly polarized-Tweetters\", fontdict = {\"fontsize\": 10})\n",
    "ax[1].set_xlabel(\"Twitter Users\", fontdict = {\"fontsize\": 12})\n",
    "ax[1].set_xticks([0.25,0.75])\n",
    "ax[1].set_xticklabels([\"Regular Users\", \"Highly Polarized\"])\n",
    "ax[1].set_ylabel(\"Number of users\", fontdict = {\"fontsize\": 12})\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"PosTwet.svg\")"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:51:36.972101Z",
     "start_time": "2022-01-18T16:51:36.283609Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"The mean Positive/Negative ratio is {:.4f}\".format(SntPerUser.PosRatio.describe()['mean']))"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:51:36.988643Z",
     "start_time": "2022-01-18T16:51:36.981525Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The user column should be discarded because classification based on the user goes against the statistics related to the fraction of positive (or negative) tweets each user posts. In particular, the mean fraction of positive tweets that each user posts is 0.5625. This value can be interpreted as an indication of not excessive polarization of the users. Therefore, while Figure (*histogram of positive tweets*) shows that there are users who exclusevely produce content associated with positive sentiment only, the number of those is not large enough do drive the mean value to one category only."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#formatting accordingly the date\n",
    "format_string = '%d %b %Y %H:%M:%S'\n",
    "date_df = dev.loc[:, [\"ids\", \"date\"]]\n",
    "date_df.date = date_df.date.progress_apply(lambda x: transformDate(x, format_string))\n",
    "date_df.sort_values(by = \"ids\", inplace = True)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:51:40.631556Z",
     "start_time": "2022-01-18T16:51:36.995967Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#visualization for the dependance between ids and date\n",
    "ids = date_df.ids.values\n",
    "dates = date_df.date.values\n",
    "fig,ax = plt.subplots(figsize = (6,4))\n",
    "\n",
    "xtick = [date_df.iloc[10000, 1], date_df.iloc[200000, 1]]\n",
    "ytick = [date_df.iloc[10000, 0], date_df.iloc[200000, 0]]\n",
    "\n",
    "ax = sns.lineplot(x = dates[::50], y = ids[::50])\n",
    "\n",
    "ax.set_xticks(xtick)\n",
    "ax.set_xticklabels(xtick, rotation = 15)\n",
    "\n",
    "ax.set_yticks(ytick)\n",
    "ax.set_yticklabels(ytick, rotation = 15)\n",
    "\n",
    "ax.grid()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"IdsDate.svg\")"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:51:41.072214Z",
     "start_time": "2022-01-18T16:51:40.634460Z"
    },
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Text Cleaning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dev[\"CleanedText\"] = dev.text.progress_apply(lambda row: text_cleaning(row))\n",
    "\n",
    "#analyzing the effects of the text_cleaning \n",
    "dev[\"IsEmpty\"] = dev.CleanedText.progress_apply(lambda x: 1 if len(x) == 0 else 0)\n",
    "emptyIdx = dev[dev.IsEmpty == 1].index\n",
    "dev.drop(columns = \"IsEmpty\", inplace = True)\n",
    "\n",
    "#discarding the empty text cells\n",
    "dev.drop(index = emptyIdx, inplace = True)\n",
    "dev.CleanedText.drop_duplicates(inplace = True)\n",
    "\n",
    "dev.sentiment.hist()"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:52:21.318269Z",
     "start_time": "2022-01-18T16:51:41.078024Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Considering the above presented structure we have decided to undersample the Positive Tweets group so to have a balanced dataset.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "posDF = dev[dev.sentiment == 1]\n",
    "negDF = dev[dev.sentiment == 0]\n",
    "\n",
    "posDF = posDF.sample(n = len(negDF), random_state = rs, replace = False, axis = 0)\n",
    "dev = pd.concat([posDF, negDF], axis = 0)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:52:21.513209Z",
     "start_time": "2022-01-18T16:52:21.324377Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Extraction\n",
    "\n",
    "In this section we experiment different vectorizers in order to select the best one. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:52:21.523474Z",
     "start_time": "2022-01-18T16:52:21.515592Z"
    },
    "code_folding": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "LR_params = {\"solver\": \"newton-cg\",\n",
    "             \"max_iter\": 500,\n",
    "             \"n_jobs\": -1,\n",
    "             \"random_state\": rs,\n",
    "             \"verbose\": 1}\n",
    "\n",
    "MAX_F = np.arange(10000, 310000, 10000)\n",
    "\n",
    "tfidf_SW_rem = {\n",
    "    \"unigrams\": [], \n",
    "    \"bigrams\": [], \n",
    "    \"trigrams\": []\n",
    "}\n",
    "\n",
    "cvec_SW_rem = {\n",
    "    \"unigrams\": [], \n",
    "    \"bigrams\": [], \n",
    "    \"trigrams\": []\n",
    "}\n",
    "y = dev.sentiment.values\n",
    "\n",
    "#removing the stopwords\n",
    "for f in tqdm(MAX_F): \n",
    "    \n",
    "    #################### COUNT VECTORIZER ####################\n",
    "    #unigrams\n",
    "    CVec_1 = CountVectorizer(ngram_range = (1,1), stop_words = \"english\", max_features = f)\n",
    "    CX1 = CVec_1.fit_transform(dev.CleanedText)\n",
    "    print(\"CVec_1:ok\")\n",
    "    #bigrams\n",
    "    CVec_2 = CountVectorizer(ngram_range = (1,2), stop_words = \"english\", max_features = f)\n",
    "    CX2 = CVec_2.fit_transform(dev.CleanedText)\n",
    "    print(\"CVec_2:ok\")\n",
    "    #trigrams\n",
    "    CVec_3 = CountVectorizer(ngram_range = (1,3), stop_words = \"english\", max_features = f)\n",
    "    CX3 = CVec_3.fit_transform(dev.CleanedText)\n",
    "    print(\"CVec_3:ok\")\n",
    "    \n",
    "    C_X1train, C_X1test, C_y1train, C_y1test = train_test_split(C_X1, y, random_state = rs, test_size = 0.05)\n",
    "    C_X2train, C_X2test, C_y2train, C_y2test = train_test_split(C_X2, y, random_state = rs, test_size = 0.05)\n",
    "    C_X3train, C_X3test, C_y3train, C_y3test = train_test_split(C_X3, y, random_state = rs, test_size = 0.05)\n",
    "    \n",
    "    #################### TFIDF ###############################\n",
    "    #unigrams\n",
    "    vec_1 = TfidfVectorizer(ngram_range = (1,1), stop_words = \"english\", max_features = f)\n",
    "    T_X1 = vec_1.fit_transform(dev.CleanedText)\n",
    "    print(\"tVec_1:ok\")\n",
    "    #bigrams\n",
    "    vec_2 = TfidfVectorizer(ngram_range = (1,2), stop_words = \"english\", max_features = f)\n",
    "    T_X2 = vec_2.fit_transform(dev.CleanedText)\n",
    "    print(\"tVec_2:ok\")\n",
    "    #trigrams\n",
    "    vec_3 = TfidfVectorizer(ngram_range = (1,3), stop_words = \"english\", max_features = f)\n",
    "    T_X3 = vec_3.fit_transform(dev.CleanedText)\n",
    "    print(\"tVec_3:ok\")\n",
    "    \n",
    "    T_X1train, T_X1test, T_y1train, T_y1test = train_test_split(T_X1, y, random_state = rs, test_size = 0.05)\n",
    "    T_X2train, T_X2test, T_y2train, T_y2test = train_test_split(T_X2, y, random_state = rs, test_size = 0.05)\n",
    "    T_X3train, T_X3test, T_y3train, T_y3test = train_test_split(T_X3, y, random_state = rs, test_size = 0.05)\n",
    "    \n",
    "    ########################### PREDICTIONS ###################\n",
    "    LR = LogisticRegression(**LR_params)\n",
    "    LR.fit(C_X1train, C_y1train)\n",
    "    cvec_SW_rem[\"unigrams\"].append(f1_score(C_y1test, LR.predict(C_X1test), average = \"macro\"))\n",
    "    \n",
    "    LR = LogisticRegression(**LR_params)\n",
    "    LR.fit(C_X2train, C_y2train)\n",
    "    cvec_SW_rem[\"bigrams\"].append(f1_score(C_y2test, LR.predict(C_X2test), average = \"macro\"))\n",
    "    \n",
    "    LR = LogisticRegression(**LR_params)\n",
    "    LR.fit(C_X3train, C_y3train)\n",
    "    cvec_SW_rem[\"trigrams\"].append(f1_score(C_y3test, LR.predict(C_X3test), average = \"macro\"))\n",
    "    \n",
    "    LR = LogisticRegression(**LR_params)\n",
    "    LR.fit(T_X1train, T_y1train)\n",
    "    tfidf_SW_rem[\"unigrams\"].append(f1_score(T_y1test, LR.predict(T_X1test), average = \"macro\"))\n",
    "    \n",
    "    LR = LogisticRegression(**LR_params)\n",
    "    LR.fit(T_X2train, T_y2train)\n",
    "    tfidf_SW_rem[\"bigrams\"].append(f1_score(T_y2test, LR.predict(T_X2test), average = \"macro\"))\n",
    "    \n",
    "    LR = LogisticRegression(**LR_params)\n",
    "    LR.fit(T_X3train, T_y3train)\n",
    "    tfidf_SW_rem[\"trigrams\"].append(f1_score(T_y3test, LR.predict(T_X3test), average = \"macro\"))    \n",
    "\n",
    "\n",
    "tfidf_with_SW = {\n",
    "    \"unigrams\": [], \n",
    "    \"bigrams\": [], \n",
    "    \"trigrams\": []\n",
    "}\n",
    "\n",
    "cvec_with_SW = {\n",
    "    \"unigrams\": [], \n",
    "    \"bigrams\": [], \n",
    "    \"trigrams\": []\n",
    "}\n",
    "\n",
    "#non removing the stopwords\n",
    "for f in tqdm(MAX_F): \n",
    "    \n",
    "    #################### COUNT VECTORIZER ####################\n",
    "    #unigrams\n",
    "    CVec_1 = CountVectorizer(ngram_range = (1,1), stop_words = None, max_features = f)\n",
    "    CX1 = CVec_1.fit_transform(dev.CleanedText)\n",
    "    print(\"CVec_1:ok\")\n",
    "    #bigrams\n",
    "    CVec_2 = CountVectorizer(ngram_range = (1,2), stop_words = None, max_features = f)\n",
    "    CX2 = CVec_2.fit_transform(dev.CleanedText)\n",
    "    print(\"CVec_2:ok\")\n",
    "    #trigrams\n",
    "    CVec_3 = CountVectorizer(ngram_range = (1,3), stop_words = None, max_features = f)\n",
    "    CX3 = CVec_3.fit_transform(dev.CleanedText)\n",
    "    print(\"CVec_3:ok\")\n",
    "    \n",
    "    C_X1train, C_X1test, C_y1train, C_y1test = train_test_split(C_X1, y, random_state = rs, test_size = 0.05)\n",
    "    C_X2train, C_X2test, C_y2train, C_y2test = train_test_split(C_X2, y, random_state = rs, test_size = 0.05)\n",
    "    C_X3train, C_X3test, C_y3train, C_y3test = train_test_split(C_X3, y, random_state = rs, test_size = 0.05)\n",
    "    \n",
    "    #################### TFIDF ###############################\n",
    "    #unigrams\n",
    "    vec_1 = TfidfVectorizer(ngram_range = (1,1), stop_words = None, max_features = f)\n",
    "    T_X1 = vec_1.fit_transform(dev.CleanedText)\n",
    "    print(\"tVec_1:ok\")\n",
    "    #bigrams\n",
    "    vec_2 = TfidfVectorizer(ngram_range = (1,2), stop_words = None, max_features = f)\n",
    "    T_X2 = vec_2.fit_transform(dev.CleanedText)\n",
    "    print(\"tVec_2:ok\")\n",
    "    #trigrams\n",
    "    vec_3 = TfidfVectorizer(ngram_range = (1,3), stop_words = None, max_features = f)\n",
    "    T_X3 = vec_3.fit_transform(dev.CleanedText)\n",
    "    print(\"tVec_3:ok\")\n",
    "    \n",
    "    T_X1train, T_X1test, T_y1train, T_y1test = train_test_split(T_X1, y, random_state = rs, test_size = 0.05)\n",
    "    T_X2train, T_X2test, T_y2train, T_y2test = train_test_split(T_X2, y, random_state = rs, test_size = 0.05)\n",
    "    T_X3train, T_X3test, T_y3train, T_y3test = train_test_split(T_X3, y, random_state = rs, test_size = 0.05)\n",
    "    \n",
    "    ########################### PREDICTIONS ###################\n",
    "    LR = LogisticRegression(**LR_params)\n",
    "    LR.fit(C_X1train, C_y1train)\n",
    "    cvec_with_SW[\"unigrams\"].append(f1_score(C_y1test, LR.predict(C_X1test), average = \"macro\"))\n",
    "    \n",
    "    LR = LogisticRegression(**LR_params)\n",
    "    LR.fit(C_X2train, C_y2train)\n",
    "    cvec_with_SW[\"bigrams\"].append(f1_score(C_y2test, LR.predict(C_X2test), average = \"macro\"))\n",
    "    \n",
    "    LR = LogisticRegression(**LR_params)\n",
    "    LR.fit(C_X3train, C_y3train)\n",
    "    cvec_with_SW[\"trigrams\"].append(f1_score(C_y3test, LR.predict(C_X3test), average = \"macro\"))\n",
    "    \n",
    "    LR = LogisticRegression(**LR_params)\n",
    "    LR.fit(T_X1train, T_y1train)\n",
    "    tfidf_with_SW[\"unigrams\"].append(f1_score(T_y1test, LR.predict(T_X1test), average = \"macro\"))\n",
    "    \n",
    "    LR = LogisticRegression(**LR_params)\n",
    "    LR.fit(T_X2train, T_y2train)\n",
    "    tfidf_with_SW[\"bigrams\"].append(f1_score(T_y2test, LR.predict(T_X2test), average = \"macro\"))\n",
    "    \n",
    "    LR = LogisticRegression(**LR_params)\n",
    "    LR.fit(T_X3train, T_y3train)\n",
    "    tfidf_with_SW[\"trigrams\"].append(f1_score(T_y3test, LR.predict(T_X3test), average = \"macro\"))    "
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:52:31.528970Z",
     "start_time": "2022-01-18T16:52:21.526372Z"
    },
    "code_folding": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we present the visualizations necessary to convey the informations presented in the previous cell. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#visualization\n",
    "fig, ax = plt.subplots(2, 1, figsize = (8,6))\n",
    "\n",
    "#removing stopwords\n",
    "ax[0] = plt.subplot(2,1,1)\n",
    "ax[0].set_title(\"MacroAvg F1 score removing stopwords\")\n",
    "t1 = ax[0].plot(MAX_F, tfidf_SW_rem[\"unigrams\"], label = \"unigrams\", linestyle = \"--\", c = \"green\")\n",
    "t2 = ax[0].plot(MAX_F, tfidf_SW_rem[\"bigrams\"], label = \"bigrams\", linestyle = \"--\", c = \"red\")\n",
    "t3 = ax[0].plot(MAX_F, tfidf_SW_rem[\"trigrams\"], label = \"trigrams\", linestyle = \"--\", c = \"blue\")\n",
    "\n",
    "c1 = ax[0].plot(MAX_F, cvec_SW_rem[\"unigrams\"], label = \"unigrams\", c = \"green\")\n",
    "c2 = ax[0].plot(MAX_F, cvec_SW_rem[\"bigrams\"], label = \"bigrams\", c = \"red\")\n",
    "c3 = ax[0].plot(MAX_F, cvec_SW_rem[\"trigrams\"], label = \"trigrams\", c = \"blue\")\n",
    "\n",
    "ax[0].set_xlabel(\"Number of features\")\n",
    "ax[0].set_ylabel(\"MacroAvg F1 score\")\n",
    "\n",
    "custom_lines = [Line2D([0], [0], color=\"green\", lw=2),\n",
    "                Line2D([0], [0], color=\"red\", lw=2),\n",
    "                Line2D([0], [0], color=\"blue\", lw=2)]\n",
    "\n",
    "CLegend = ax[0].legend(custom_lines, [\"unigrams\", \"bigrams\", \"trigram\"], loc = (1.01,0.1))\n",
    "\n",
    "custom_stiles = [Line2D([0], [0], color = \"grey\", ls=\"--\"),\n",
    "                Line2D([0], [0], color = \"grey\", ls=\"-\")]\n",
    "\n",
    "ax[0].grid()\n",
    "ax[0].legend(custom_stiles, [\"TfIdf\", \"CVec\"], loc = (1.04, 0.45))\n",
    "ax[0].add_artist(CLegend)\n",
    "\n",
    "#non removing stopwords\n",
    "ax[1] = plt.subplot(2,1,2)\n",
    "ax[1].set_title(\"MacroAvg F1 score without removing stopwords\")\n",
    "t1 = ax[1].plot(MAX_F, tfidf_with_SW[\"unigrams\"], label = \"unigrams\", linestyle = \"--\", c = \"green\")\n",
    "t2 = ax[1].plot(MAX_F, tfidf_with_SW[\"bigrams\"], label = \"bigrams\", linestyle = \"--\", c = \"red\")\n",
    "t3 = ax[1].plot(MAX_F, tfidf_with_SW[\"trigrams\"], label = \"trigrams\", linestyle = \"--\", c = \"blue\")\n",
    "\n",
    "c1 = ax[1].plot(MAX_F, cvec_with_SW[\"unigrams\"], label = \"unigrams\", c = \"green\")\n",
    "c2 = ax[1].plot(MAX_F, cvec_with_SW[\"bigrams\"], label = \"bigrams\", c = \"red\")\n",
    "c3 = ax[1].plot(MAX_F, cvec_with_SW[\"trigrams\"], label = \"trigrams\", c = \"blue\")\n",
    "\n",
    "ax[1].set_xlabel(\"Number of features\")\n",
    "ax[1].set_ylabel(\"MacroAvg F1 score\")\n",
    "\n",
    "custom_lines = [Line2D([0], [0], color=\"green\", lw=2),\n",
    "                Line2D([0], [0], color=\"red\", lw=2),\n",
    "                Line2D([0], [0], color=\"blue\", lw=2)]\n",
    "\n",
    "CLegend = ax[1].legend(custom_lines, [\"unigrams\", \"bigrams\", \"trigram\"], loc = (1.01,0.1))\n",
    "\n",
    "custom_stiles = [Line2D([0], [0], color = \"grey\", ls=\"--\"),\n",
    "                Line2D([0], [0], color = \"grey\", ls=\"-\")]\n",
    "\n",
    "ax[1].grid()\n",
    "ax[1].legend(custom_stiles, [\"TfIdf\", \"CVec\"], loc = (1.04, 0.45))\n",
    "ax[1].add_artist(CLegend)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"VecResults.svg\")"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:52:31.577783Z",
     "start_time": "2022-01-18T16:51:29.229Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model\n",
    "\n",
    "Considering the scant improvement consequent to: \n",
    "\n",
    "1) **increasing the value of max_features from 200k to 300k**\n",
    "\n",
    "2) **adopting trigrams for the vectorization**\n",
    "\n",
    "We resorted to set max_features to 200k and using bigrams. This improved the efficiency of the computation. \n",
    "We tested out three models: \n",
    "\n",
    "1) *Logistic Regression*\n",
    "\n",
    "2) *Multinomial Naive Bayes Classifier*\n",
    "\n",
    "3) *Linear SVC*\n",
    "\n",
    "In this section we present the results of these experiments having fixed the vectorization as above mentioned. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vec_2 = TfidfVectorizer(ngram_range = (1,2), max_features = 200000, stop_words = None)\n",
    "Xgrid = vec_2.fit_transform(dev.CleanedText)\n",
    "print(\"Vectorization completed!\")\n",
    "y = dev.sentiment.values"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:52:43.052866Z",
     "start_time": "2022-01-18T16:52:36.411819Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "LR = LogisticRegression(n_jobs = -1, random_state = rs)\n",
    "SVC = LinearSVC(random_state = rs, verbose = 1)\n",
    "M_NB = MultinomialNB()\n",
    "\n",
    "Xtrain, X_test, ytrain, y_test = train_test_split(Xgrid, y, test_size = 0.05, random_state = rs)\n",
    "LR.fit(Xtrain, ytrain)\n",
    "SVC.fit(Xtrain, ytrain)\n",
    "M_NB.fit(Xtrain, ytrain)\n",
    "\n",
    "\n",
    "LRy_pred_proba = LR.predict_proba(X_test)[::,1]\n",
    "SVCy_pred_proba = SVC._predict_proba_lr(X_test)[::,1]\n",
    "MNBy_pred_proba = M_NB.predict_proba(X_test)[::,1]\n",
    "\n",
    "#logistic regression\n",
    "LRauc = roc_auc_score(y_test, LRy_pred_proba)\n",
    "\n",
    "#svc\n",
    "SVCauc = roc_auc_score(y_test, SVCy_pred_proba)\n",
    "\n",
    "#multinomial\n",
    "MNBauc = roc_auc_score(y_test, MNBy_pred_proba)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:52:54.856401Z",
     "start_time": "2022-01-18T16:52:44.814715Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#logistic regression\n",
    "LR_f1 = f1_score(y_test, LR.predict(X_test))\n",
    "\n",
    "#svc\n",
    "SVC_f1 = f1_score(y_test, SVC.predict(X_test))\n",
    "\n",
    "#multinomial\n",
    "MNB_f1 = f1_score(y_test, M_NB.predict(X_test))"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:52:55.420697Z",
     "start_time": "2022-01-18T16:52:55.393166Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Logistic Regression\", \"|\", LRauc, \"|\", LR_f1)\n",
    "print(\"Linear SVC         \", \"|\",SVCauc, \"|\", SVC_f1)\n",
    "print(\"MN Bayes           \", \"|\",MNBauc, \"|\", MNB_f1)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:52:55.943673Z",
     "start_time": "2022-01-18T16:52:55.939229Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Considering these results, we have chosen to further explore for the hyperparamether tuning fase the Logistic Regression Classifier, considering the fact that while there is certainly a small margin (0.01) that it makes it better than the others, Logistic Regression is fully interpretable. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Grid search"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we perform a Grid Search with cross validation in order to obtain the best possible set of hyperparamethers."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "f1_scorer = make_scorer(f1_score, average = \"macro\")\n",
    "\n",
    "params = {\n",
    "    \"verbose\": [1], \n",
    "    \"n_jobs\": [-1],\n",
    "    \"random_state\": [rs],\n",
    "    \"C\": np.linspace(0.01, 5, 100)\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(LogisticRegression(), \n",
    "                  params, \n",
    "                  scoring = f1_scorer,\n",
    "                  cv = 8,\n",
    "                  refit = True, verbose = 10)\n",
    "\n",
    "clf.fit(Xgrid, y)\n",
    "bestLR = clf.best_estimator_"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:52:31.591202Z",
     "start_time": "2022-01-18T16:51:29.242Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Best parameters are: \")\n",
    "print(\"********************\")\n",
    "bestP = bestLR.get_params()\n",
    "pprint.pprint(bestP)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:52:31.593069Z",
     "start_time": "2022-01-18T16:51:29.243Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model evaluation "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we use different metrics to evaluate the performance of the best classifier we have found in the hyperparamether tuning. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#at first we instiate a new classifier (with the best parameters) and we train it on the 95% of the data\n",
    "roc_LR = LogisticRegression(**bestP)\n",
    "Xtrain, X_test, ytrain, y_test = train_test_split(Xgrid, y, test_size = 0.05, random_state = rs)\n",
    "roc_LR.fit(Xtrain, ytrain)\n",
    "\n",
    "#we then obtain the roc curve\n",
    "y_pred_proba = roc_LR.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = roc_curve(y_test,  y_pred_proba)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:56:51.680425Z",
     "start_time": "2022-01-18T16:56:46.368095Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots(figsize = (6,4))\n",
    "\n",
    "axx = plt.plot(fpr, tpr, label = \"AUC = {:.2f}\".format(auc), color = \"r\")\n",
    "\n",
    "ax.set_title(\"ROC Curve\")\n",
    "ax.set_ylabel('True Positive Rate', fontdict = {\"fontsize\": 13})\n",
    "ax.set_xlabel('False Positive Rate', fontdict = {\"fontsize\": 13})\n",
    "ax.plot([0,1], [0,1], \"k--\")\n",
    "ax.legend(loc = \"lower right\")\n",
    "fig.savefig(\"RocCurve.svg\")"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:56:52.505511Z",
     "start_time": "2022-01-18T16:56:52.281499Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#here we present the confusion matrix for our classifier\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "plot_confusion_matrix(roc_LR, X_test, y_test, ax = ax,\n",
    "                        display_labels = [\"Positive\", \"Negative\"], cmap = \"magma\")  \n",
    "fig.savefig(\"ConfMatrix.svg\")"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:56:56.839221Z",
     "start_time": "2022-01-18T16:56:56.603502Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"F1 Score reached by the model is {:.4f}\".format(f1_score(y_test, roc_LR.predict(X_test), average = \"macro\")))"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:56:57.461820Z",
     "start_time": "2022-01-18T16:56:57.449037Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Submission\n",
    "\n",
    "For the submission (i.e., the prediction on the evaluation set) we use a classifier which is fitted on the whole Xgrid, i.e. the classifier returned by the GridSearch. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#importing the evaluation data\n",
    "ev = dt.fread(\"./data/evaluation.csv\").to_pandas()\n",
    "\n",
    "#cleaning the text\n",
    "ev[\"CleanedText\"] = ev.text.progress_apply(text_cleaning)\n",
    "\n",
    "#vectorizing the text with the vectorizer fitted during training\n",
    "Xev = vec_2.transform(ev.CleanedText)\n",
    "yev = bestLR.predict(Xev)\n",
    "\n",
    "#creating a csv for the submission\n",
    "subs = pd.DataFrame(index = ev.index)\n",
    "subs.index.name = \"Id\"\n",
    "subs[\"Predicted\"] = yev\n",
    "\n",
    "subs.to_csv(\"FinalSubmission.csv\")"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:57:40.036037Z",
     "start_time": "2022-01-18T16:57:24.067712Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Explation\n",
    "\n",
    "Here we present the top words that influence the sentiment attribution"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "neg_couples = sorted(list(zip(bestLR.coef_.reshape(-1,1), vec_2.get_feature_names())))\n",
    "pos_couples = sorted(list(zip(bestLR.coef_.reshape(-1,1), vec_2.get_feature_names())), reverse = True)\n",
    "\n",
    "N = 5"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:57:46.979912Z",
     "start_time": "2022-01-18T16:57:40.786567Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "words = pd.DataFrame()\n",
    "words[\"Positive Words\"] = [pos_couples[j][1] for j in range(N)]\n",
    "words[\"Negative Words\"] = [neg_couples[j][1] for j in range(N)]\n",
    "print(words)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-18T16:58:09.774290Z",
     "start_time": "2022-01-18T16:58:09.766233Z"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a1747fee551ae34cd538edc0c05a45a7003e9ca43004ebfc645a328407c7bf8"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "537.841px",
    "left": "813.454px",
    "right": "20px",
    "top": "34px",
    "width": "691.008px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
